### Hi there 👋

### :heavy_check_mark: 核心创新点：
- 1：使用数据增强的方式避免数据过拟合（训练的方式）
- 2：将Transformer应用在小数据集上，突破了小数据集的瓶颈
- 2.1:结合CNN提取特征和注意力的机制，使用Transformer解决远距离依赖的问题
- 2.2：将图片分成两种，一种是用CNN和Attention机制，另一种是使用CeiT，两者作为embedding结合提取不同尺度的特征
- 2.3: 使用SSformer 在小数据集上使用
- 3.4: 使用No-Local在小数据集上使用
- 3：在降低模型的参数量（模型压缩或知识蒸馏）的同时依旧达到很高的精度
- 4：使用注意力机制增强神经网络的可解释性
- 5：在老的模型下发现新的问题，发现新的任务；
- 6：SCR模块换成Transformer才对，或者时间序列里面参考的东西
- 7：如何定义一个新的问题~~
- 8：实验的结果的可视化操作
### :gear: 论文理解相关的：
- 1；明确模型的每个部分的输入和输出，探究每个模块的意义，探究每个模块的必要性（消融实验）
- 2：有必要在SCR模块将模型变成四维的部分？4D卷积有什么用；
- 2.1：这里提到4D卷积的原因是可以有效逼近原始4D卷积在内存和时间方面的效率？会有一些牵强，那这些和图像有什么关系呢？
- 3：明确论文的公式计算和每个公式代表的含义
- 4：为什么SCR模块可以保留丰富的语义信息，但做分类也没有使用语义信息？
- 5：为什么在SCR模块使用relu激活函数呢？
- 6：在计算相似度的时候使用余弦相似度，换个相似度呢
### :books: 模型结构改进相关的：
- 1：找到可以插入的模型，例如在模型的最后部分，q和k和v；探究attention的+和*的连接方式
- 1.1：transformer重新开始学的时候也许会很慢，但在模型的后面刚好是一维度，可以接transformer
- 1.2：也不一定是trasnfformer，是Attention也可以的；
- 2：在CCA模块阶段丢失了C做卷积，在过往的论文中一般都是H*W*C相关的，还没有出现没有C的
- 3：什么时间模型需要权重共享，孪生网络可以嵌入在哪里，如何提高识别的效率
- 4：逐点做卷积，大大增加了模型的训练时间（消融实验探究模型的训练）
- 5：设计encoder和decoder和更好的分类器（线性权重分类器可以加进去），参考其他模型的结构
- 6：结合SENet的思想，使用多个网络结构进行测试：在SC的模块加入一些新的卷积模块测试****************
- 7：SCR需要多个模块吗？CC需要多个模块吗（消融实验测试？）*****************
- 8：CCA和SCR的先后顺序或者交叉，为什么只是先自相关再互相关，是不是也可以先互相关再自相关再互相关？
- 9：减少模型的参数量，降低模型的参数量，SCR（157.K，CCA45.8K）-**************
- 10：模型训练的过程是如何的？每个数据集的参数量？数据集中的图片涨什么样子？
- 11：显著性的Co-Saliency的和CO-correlation类似，是否可以尝试改进一下；
- 12：将3*3的卷积使用MHSA替代-（BOTNet的思想）https://www.zhihu.com/question/442344643/answer/1744876036
- 13：将CCA模块换成V，SCR模块生成的变成Q和K，增加了计算量
- 14:  探究4D卷积的必要性，小数据集上没必要到高纬的空间，验证4D卷积的必要性
### :deciduous_tree: 项目代码相关的：
- 1：f模块的encoder中，使用resnet
- 2：为什么在SCR模块卷积部分那里使用5*5的卷积，大卷积和小卷积的区别
- 3：为什么之前SCR模块加入BN和RELU在CCA模块没有加入BN和CCa
###  :pushpin: 数据集和训练相关的：
- 1：是否还有更好的训练方式，元学习或者其他的，每次将每个query和support做对比，效率是不是有点低？
- 2：在模型的训练过程中，每个数据集在训练集达到84%左右，测试集只有65%，明显模型过拟合！-求均值均到了70%多或者80%多，但明显越训练，越过拟合！-（靠一些tricks吗还是做消融实验探究）https://zhuanlan.zhihu.com/p/78792533
- 3：CO-rellation的过程中和元学习有什么关系呢？
- 4：训练的方式的改进有哪些？
- 5：把分类分错的样本打印出来，看看哪里出问题了，找到问题！
- 6：将Transformer应用在小数据集上，可以针对老的Transformer进行对比实验，与经典的模型进行对比实验，
- 7：知识蒸馏：https://blog.csdn.net/qq_39685733/article/details/108312333